{
    "Missions": {
        "taskstitle": "Quelques taches réalisées...",
        "toolstitle": "Les technologies majeures",
        "bouygues": {
            "title": "DevOps BigData ",
            "location": "Bouygues Telecom",
            "dateShort": "2019-2021",
            "description": "Dans cette première mission, j'ai intégré une équipe de 3 DevOps et 3 developpeurs afin de renforcer le besoin de Bouygues sur l'implémentation d’une nouvelle plateforme.\n\nLe besoin métier était de collecter, agréger et indexer des données de télécommunication (log d'antenne, router, etc.) et les servir dans un cluster Hadoop pour des besoins BI. En finalité le client voulait construire sa plateforme afin de développer à terme des intelligences artificielles pouvant détecter des pannes sur le réseau Bouygues par exemple.",
            "tasks": "Intégration Kubernetes : Pour des contraintes de sécurité, le client ne souhaitait pas faire sa migration vers le cloud et avait à coeur de garder son infrastructure sur des datacenters français. La mise en place de cluster Kubernetes s'est donc fait baremetal sur des machines fournies par le client.\nIntégration HortonWorks : Mise en place de cluster BigData Hadoop (anciennement HortonWorks) afin de servir de socle technique pour servir la data au data scientist côté client.\nIndustrialisation de l'infrastructure avec Ansible :  Développement de recette afin d'industrialiser le déploiement de l'ensemble de l'infrastructure (cluster Kubernetes et cluster Hadoop)\nImplémentation du monitoring et alerting avec Prometheus, Grafana et Alertmanager : Collecte des métrics pertinentes dans Prometheus et création de règles d'alerting. Création de dashboard Grafana. Mise en place d'une politique de cycle de vie des métrics Prometheus, le client souhaitait pouvoir conserver un historique assez conséquent de ces données."
        },
        "altrnativ": {
            "title": "DevOps BigData ",
            "location": "Altrnativ",
            "dateShort": "2021-2021",
            "description": "Dans cette mission, le cahier des charges était de design et d'implémenter une nouvelle infrastructure pour collecter, agréger et indexer des données télécommunication et les servir dans un cluster Hadoop pour des besoins Data science.\n\nLe client avait déjà eu vent de la réalisation apporté au sein du groupe Bouygues et souhaité répliquer la même infrastructure pour des besoins similaires.",
            "tasks": "Intégration Kubernetes : Par choix, le client souhaitait une installation locale de son infrastructure et non sur un cloud provider. L'implémentation s'est donc faite sur des machines fournies par le client.\nIntégration HortonWorks : Mise en place de cluster BigData Hadoop (anciennement HortonWorks) afin de servir de socle technique pour servir la data au data scientist côté client.\nIndustrialisation de l'infrastructure avec Ansible : Développement de recette afin d'industrialiser le déploiement de l'ensemble de l'infrastructure (cluster Kubernetes et cluster Hadoop)\nImplémentation du monitoring et alerting avec Prometheus, Grafana et Alertmanager : Collecte des métrics pertinentes dans Prometheus et création de règles d'alerting. Création de dashboard Grafana. Mise en place d'une politique de cycle de vie des métrics Prometheus, le client souhaitait pouvoir conserver un historique assez conséquent de ces données."
        },
        "cdiscount": {
            "title": "SRE/DevOps ",
            "location": "Cdiscount",
            "dateShort": "2021-2022",
            "description": "Cdiscount est le leader français de l'e-commerce B2C et de la logistique et concurrent d'Amazon sur le territoire français.\n\nIntégré au sein de l'équipe SRE (~ 8 personnes), j'ai eu la responsabilité de développer et manager la majeur partie de plateforme Cdiscount, hébergée sur plusieurs datacenter.\n\nCdiscount navigue a contre courant, souhaitant conserver la gestion en interne, plutôt que de consommer son infrastructure sur un cloud provider en mode Plateform as a Service. C'est pourquoi cette mission très formatrice, m'a permis de développer mes compétences sur l'infrastructure as code via Ansible et Terraform.\n\nUne autre partie de cette mission était de moderniser la solution de stockage distribué pour Kubernetes en utilisant Rook-Ceph",
            "tasks": "Développement et management des cluster Kubernetes : Rédaction de recette Ansible et plan Terraform afin d'administrer et d'industrialiser l'infrastructure.\nIntégration de la solution de stockage répliquée rook-ceph pour le stateful dans Kubernetes : Un cluster dédiés Ceph était déjà présent, mais trop lourd à manager, le choix a donc été fait de transiter cette technologie dans Kubernetes pour simplifier sa gestion.\nDéveloppement pipeline CI/CD : pour les équipes de développement et SRE"
        },
        "mirakl": {
            "title": "SRE/DevOps ",
            "location": "Mirakl",
            "dateShort": "2022-now",
            "description": "Mirakl, véritable licorne française et leader du e-commerce français B2B, à vu ses effectifs grossir et exploser ces dernières années.\n\nC'est pour répondre à ce besoin que j'ai rejoint, pour ma première mission en freelance, l'équipe SRE d'une quinzaine de personnes, afin de les aider dans la gestion de l'infrastructure multi cloud (GCP, AWS & Azure).\n\nTrès proche de la culture DevOps, Mirakl a cependant accumulé de la dette technique à cause de sa croissance exponentielle. L'un des premiers sujets de cette mission est de moderniser toute la partie infrastructure as code : Terraform, les pipelines CD en intégrant ArgoCD, mais aussi moderniser la partie base de données en l'intégrant dans Kubernetes via Cloudnative PG.",
            "tasks": "Refactorisation de l'infrastructure as code : Le client avait accumulé de la dette technique sur la partie IaC Terraform. L'ensemble des modules et resources vivaient dans un mono repo. L'objectif a donc été de redécouper et restructurer les modules Terraform, les faire vivre et releasé dans des repo dédiés afin de simplifier la gestion.\nDéveloppement de nouveau cluster Kubernetes : Refonte des cluster existant en utilisant la nouvelle stack Terraform sur AWS et GCP, ouverture de nouveau sur Azure.\nRefactorisation de la partie Git-Ops : identique à la stack IaC, la partie Git-Ops vivait dans un mono repo. Là encore l'objectif était de refactoriser l'ensemble afin de découper le packaging d'application poussée côté Kubernets dans des repos dédiés. La solution choisie : créer des chart Helm dédié par application et orchestrer l'ensemble via ArgoCD\nIntégration d'un bastion au sein de l'infra : Nous avons choisi Teleport pour répondre au besoin d'accès Kubernetes, DB, Kafka, et autres applications proxifiées par Teleport.\nMigration de DB dans Kubernetes avec Cloudnative PG : La partie base de données est l'un des sujet lourd de Mirakl. Il était donc tout naturel de trouver un moyen d'alléger cette partie là. Le projet Cloudnative PG nous a paru concluant, nous permettant de faire vivre nos databases à l'intérieur de Kubernetes et ainsi de profiter de sa souplesse, de sa stabilité et sa résilience."
        }
    }
}
